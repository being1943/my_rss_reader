import json
import os
import pprint
import re
import shutil
import time
from datetime import datetime
from multiprocessing import Pool, Manager
from urllib.parse import urlparse

import feedparser
import pytz
import requests
import yagmail


def get_rss_info(feed_url, index, rss_info_list):
    result = {"result": []}
    request_success = False
    # å¦‚æœè¯·æ±‚å‡ºé”™,åˆ™é‡æ–°è¯·æ±‚,æœ€å¤šäº”æ¬¡
    for i in range(3):
        if not request_success:
            try:
                headers = {
                    # è®¾ç½®ç”¨æˆ·ä»£ç†å¤´(ä¸ºç‹¼æŠ«ä¸Šç¾Šçš®)
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36",
                    "Content-Encoding": "gzip"
                }
                # ä¸‰æ¬¡åˆ†åˆ«è®¾ç½®8, 16, 24ç§’é’Ÿè¶…æ—¶
                feed_url_content = requests.get(feed_url, timeout=(i + 1) * 8, headers=headers).content
                feed = feedparser.parse(feed_url_content)
                feed_entries = feed["entries"]
                feed_entries_length = len(feed_entries)
                print("==feed_url=>>", feed_url, "==len=>>", feed_entries_length)
                for entrie in feed_entries[0: feed_entries_length - 1]:
                    title = entrie["title"]
                    link = entrie["link"]
                    date = time.strftime("%Y-%m-%d", entrie["published_parsed"])

                    title = title.replace("\n", "")
                    title = title.replace("\r", "")

                    result["result"].append({
                        "title": title,
                        "link": link,
                        "date": date
                    })
                request_success = True
            except Exception as e:
                print(feed_url + "ç¬¬+" + str(i) + "+æ¬¡è¯·æ±‚å‡ºé”™==>>", e)
                pass
        else:
            pass

    rss_info_list[index] = result["result"]
    print("æœ¬æ¬¡çˆ¬å–==ã€‹ã€‹", feed_url, "<<<===", index, result["result"])
    pprint.pp(result)
    # å‰©ä½™æ•°é‡
    remaining_amount = 0

    for tmp_rss_info_atom in rss_info_list:
        if isinstance(tmp_rss_info_atom, int):
            remaining_amount = remaining_amount + 1

    print("å½“å‰è¿›åº¦ | å‰©ä½™æ•°é‡", remaining_amount, "å·²å®Œæˆ==>>", len(rss_info_list) - remaining_amount)
    return result["result"]


def send_mail(email, title, contents):
    # åˆ¤æ–­secret.jsonæ˜¯å¦å­˜åœ¨
    try:
        with open(os.path.join(os.getcwd(), "secret.json"), 'r', encoding='utf-8') as load_f:
            load_dict = json.load(load_f)
            user = load_dict["user"]
            password = load_dict["password"]
            host = load_dict["host"]
            # print(load_dict)
            yag = yagmail.SMTP(user=user, password=password, host=host)
            # å‘é€é‚®ä»¶
            yag.send(email, title, contents)
    except:
        print("å‘é€é‚®ä»¶å¤±è´¥")

    # è¿æ¥é‚®ç®±æœåŠ¡å™¨
    # yag = yagmail.SMTP(user=user, password=password, host=host)


def replace_readme():
    # è¯»å–EditREADME.md
    print("replace_readme")
    with open(os.path.join(os.getcwd(), "EditREADME.md"), 'r', encoding='utf-8') as load_f:
        edit_readme_md = load_f.read();

        before_info_list = re.findall(r'\{\{latest_content\}\}.*\[è®¢é˜…åœ°å€\]\(.*\)', edit_readme_md);
        # å¡«å……ç»Ÿè®¡RSSæ•°é‡
        # å¡«å……ç»Ÿè®¡æ—¶é—´
        ga_rss_datetime = datetime.fromtimestamp(int(time.time()), pytz.timezone('Asia/Shanghai')).strftime(
            '%Y-%m-%d %H:%M:%S')

        new_edit_readme_md = edit_readme_md \
            .replace("{{rss_num}}", str(len(before_info_list))) \
            .replace("{{ga_rss_datetime}}", str(ga_rss_datetime))
        # ä½¿ç”¨è¿›ç¨‹æ± è¿›è¡Œæ•°æ®è·å–ï¼Œè·å¾—rss_info_list
        before_info_list_len = len(before_info_list)
        rss_info_list = Manager().list(range(before_info_list_len))
        print('åˆå§‹åŒ–å®Œæ¯•==ã€‹', rss_info_list)

        # åˆ›å»ºä¸€ä¸ªæœ€å¤šå¼€å¯8è¿›ç¨‹çš„è¿›ç¨‹æ± 
        po = Pool(8)

        for index, before_info in enumerate(before_info_list):
            # è·å–link
            link = re.findall(r'\[è®¢é˜…åœ°å€\]\((.*)\)', before_info)[0]
            po.apply_async(get_rss_info, (link, index, rss_info_list))

        # å…³é—­è¿›ç¨‹æ± ,ä¸å†æ¥æ”¶æ–°çš„ä»»åŠ¡,å¼€å§‹æ‰§è¡Œä»»åŠ¡
        po.close()

        # ä¸»è¿›ç¨‹ç­‰å¾…æ‰€æœ‰å­è¿›ç¨‹ç»“æŸ
        po.join()
        pprint.pprint(list(rss_info_list))

        for index, before_info in enumerate(before_info_list):
            # è·å–link
            link = re.findall(r'\[è®¢é˜…åœ°å€\]\((.*)\)', before_info)[0]
            # ç”Ÿæˆè¶…é“¾æ¥
            rss_acticle_list = rss_info_list[index]
            parse_result = urlparse(link)
            scheme_netloc_url = str(parse_result.scheme) + "://" + str(parse_result.netloc)

            # åŠ å…¥åˆ°ç´¢å¼•
            try:
                new_num, today_news_list = extract_today_rss(rss_acticle_list)
            except:
                print("An exception occurred")
            latest_content = ''
            for rss_acticle in rss_acticle_list[:5]:
                latest_content = latest_content + " â€£ " + f'<a href="{rss_acticle["link"]}" target="_blank">{rss_acticle["title"]}</a><br/>'

            if not latest_content:
                latest_content = "[æš‚æ— æ³•é€šè¿‡çˆ¬è™«è·å–ä¿¡æ¯, ç‚¹å‡»è¿›å…¥æºç½‘ç«™ä¸»é¡µ](" + scheme_netloc_url + ")"
            # if len(rss_acticle_list) > 0:
            #     rss_acticle_list[0]["title"] = rss_acticle_list[0]["title"].replace("|", "\|")
            #     rss_acticle_list[0]["title"] = rss_acticle_list[0]["title"].replace("[", "\[")
            #     rss_acticle_list[0]["title"] = rss_acticle_list[0]["title"].replace("]", "\]")
            #
            #     latest_content = "[" + rss_acticle_list[0]["title"] + (" ğŸŒˆ " + rss_acticle_list[0]["date"] if (
            #             rss_acticle_list[0]["date"] == datetime.today().strftime("%Y-%m-%d")) else " \| " +
            #                                                                                        rss_acticle_list[0][
            #                                                                                            "date"]) + "](" + \
            #                      rss_acticle_list[0]["link"] + ")"
            #
            # if len(rss_acticle_list) > 1:
            #     rss_acticle_list[1]["title"] = rss_acticle_list[1]["title"].replace("|", "\|")
            #     rss_acticle_list[1]["title"] = rss_acticle_list[1]["title"].replace("[", "\[")
            #     rss_acticle_list[1]["title"] = rss_acticle_list[1]["title"].replace("]", "\]")
            #
            #     latest_content = latest_content + "<br/>[" + rss_acticle_list[1]["title"] + (
            #         " ğŸŒˆ " + rss_acticle_list[0]["date"] if (
            #                 rss_acticle_list[0]["date"] == datetime.today().strftime("%Y-%m-%d")) else " \| " +
            #                                                                                            rss_acticle_list[
            #                                                                                                0][
            #                                                                                                "date"]) + "](" + \
            #                      rss_acticle_list[1]["link"] + ")"

            # ç”Ÿæˆafter_info
            after_info = before_info.replace("{{latest_content}}", latest_content)
            print("====latest_content==>", latest_content)
            # æ›¿æ¢edit_readme_mdä¸­çš„å†…å®¹
            new_edit_readme_md = new_edit_readme_md.replace(before_info, after_info)

    # æ›¿æ¢EditREADMEä¸­çš„ç´¢å¼•
    new_edit_readme_md = new_edit_readme_md.replace("{{news}}", ''.join(today_news_list))
    # æ›¿æ¢EditREADMEä¸­çš„æ–°æ–‡ç« æ•°é‡ç´¢å¼•
    new_edit_readme_md = new_edit_readme_md.replace("{{new_num}}", str(new_num))
    # æ·»åŠ CDN
    new_edit_readme_md = new_edit_readme_md.replace("./_media",
                                                    "https://cdn.jsdelivr.net/gh/zhaoolee/garss/_media")

    # å°†æ–°å†…å®¹
    with open(os.path.join(os.getcwd(), "README.md"), 'w', encoding='utf-8') as load_f:
        load_f.write(new_edit_readme_md)
    return new_edit_readme_md


def extract_today_rss(rss_acticle_list):
    new_num = 0
    today_news_list = list()
    """è·å–ä»Šæ—¥Rssä¿¡æ¯æ”¾åˆ°æ–°é—»"""
    for rss_acticle in rss_acticle_list:
        if rss_acticle["date"] == datetime.today().strftime("%Y-%m-%d"):
            new_num = new_num + 1
            today_news_list.append(
                f"<div style='line-height:3;{'background-color:#FAF6EA;' if new_num % 2 == 0 else ''}'>"
                f"<a href='{rss_acticle['link']}' style='line-height:2;text-decoration:none;display:block;color:#584D49;' target='_blank'>ğŸŒˆ {new_num}. {rss_acticle['title']}</a></div>")
    return new_num, today_news_list


# å°†README.mdå¤åˆ¶åˆ°docsä¸­

def cp_readme_md_to_docs():
    shutil.copyfile(os.path.join(os.getcwd(), "README.md"), os.path.join(os.getcwd(), "docs", "README.md"))


def cp_media_to_docs():
    if os.path.exists(os.path.join(os.getcwd(), "docs", "_media")):
        shutil.rmtree(os.path.join(os.getcwd(), "docs", "_media"))
    shutil.copytree(os.path.join(os.getcwd(), "_media"), os.path.join(os.getcwd(), "docs", "_media"))


def get_email_list():
    email_list = []
    with open(os.path.join(os.getcwd(), "tasks.json"), 'r', encoding='utf-8') as load_f:
        load_dic = json.load(load_f)
        for task in load_dic["tasks"]:
            email_list.append(task["email"])
    return email_list


# åˆ›å»ºopmlè®¢é˜…æ–‡ä»¶

def create_opml():
    result = "";
    result_v1 = "";

    # <outline text="CNET News.com" description="Tech news and business reports by CNET News.com. Focused on information technology, core topics include computers, hardware, software, networking, and Internet media." htmlUrl="http://news.com.com/" language="unknown" title="CNET News.com" type="rss" version="RSS2" xmlUrl="http://news.com.com/2547-1_3-0-5.xml"/>

    with open(os.path.join(os.getcwd(), "EditREADME.md"), 'r', encoding='utf-8') as load_f:
        edit_readme_md = load_f.read();

        ## å°†ä¿¡æ¯å¡«å……åˆ°opml_info_list
        opml_info_text_list = re.findall(r'.*\{\{latest_content\}\}.*\[è®¢é˜…åœ°å€\]\(.*\).*', edit_readme_md);

        for opml_info_text in opml_info_text_list:
            # print('==', opml_info_text)

            opml_info_text_format_data = re.match(r'\|(.*)\|(.*)\|(.*)\|(.*)\|.*\[è®¢é˜…åœ°å€\]\((.*)\).*\|',
                                                  opml_info_text)

            # print("data==>>", opml_info_text_format_data)

            # print("æ€»ä¿¡æ¯", opml_info_text_format_data[0].strip())
            # print("ç¼–å·==>>", opml_info_text_format_data[1].strip())
            # print("text==>>", opml_info_text_format_data[2].strip())
            # print("description==>>", opml_info_text_format_data[3].strip())
            # print("data004==>>", opml_info_text_format_data[4].strip())
            print('##', opml_info_text_format_data[2].strip())
            print(opml_info_text_format_data[3].strip())
            print(opml_info_text_format_data[5].strip())

            opml_info = {}
            opml_info["text"] = opml_info_text_format_data[2].strip()
            opml_info["description"] = opml_info_text_format_data[3].strip()
            opml_info["htmlUrl"] = opml_info_text_format_data[5].strip()
            opml_info["title"] = opml_info_text_format_data[2].strip()
            opml_info["xmlUrl"] = opml_info_text_format_data[5].strip()

            # print('opml_info==>>', opml_info);

            opml_info_text = '<outline  text="{text}" description="{description}" htmlUrl="{htmlUrl}" language="unknown" title="{title}" type="rss" version="RSS2" xmlUrl="{xmlUrl}"/>'

            opml_info_text_v1 = '      <outline text="{title}" title="{title}" type="rss"  \n            xmlUrl="{xmlUrl}" htmlUrl="{htmlUrl}"/>'

            opml_info_text = opml_info_text.format(
                text=opml_info["text"],
                description=opml_info["description"],
                htmlUrl=opml_info["htmlUrl"],
                title=opml_info["title"],
                xmlUrl=opml_info["xmlUrl"]
            )

            opml_info_text_v1 = opml_info_text_v1.format(
                htmlUrl=opml_info["htmlUrl"],
                title=opml_info["title"],
                xmlUrl=opml_info["xmlUrl"]
            )

            result = result + opml_info_text + "\n"

            result_v1 = result_v1 + opml_info_text_v1 + "\n"

    zhaoolee_github_garss_subscription_list = "";
    with open(os.path.join(os.getcwd(), "rss-template-v2.txt"), 'r', encoding='utf-8') as load_f:
        zhaoolee_github_garss_subscription_list_template = load_f.read();
        GMT_FORMAT = '%a, %d %b %Y %H:%M:%S GMT'
        date_created = datetime.utcnow().strftime(GMT_FORMAT);
        date_modified = datetime.utcnow().strftime(GMT_FORMAT);
        zhaoolee_github_garss_subscription_list = zhaoolee_github_garss_subscription_list_template.format(result=result,
                                                                                                          date_created=date_created,
                                                                                                          date_modified=date_modified);
        # print(zhaoolee_github_garss_subscription_list);

    # å°†å†…å®¹å†™å…¥
    with open(os.path.join(os.getcwd(), "zhaoolee_github_garss_subscription_list_v2.opml"), 'w',
              encoding='utf-8') as load_f:
        load_f.write(zhaoolee_github_garss_subscription_list)

    zhaoolee_github_garss_subscription_list_v1 = ""
    with open(os.path.join(os.getcwd(), "rss-template-v1.txt"), 'r', encoding='utf-8') as load_f:
        zhaoolee_github_garss_subscription_list_template = load_f.read();
        zhaoolee_github_garss_subscription_list_v1 = zhaoolee_github_garss_subscription_list_template.format(
            result=result_v1);
        # print(zhaoolee_github_garss_subscription_list_v1);

    # å°†å†…å®¹å†™å…¥
    with open(os.path.join(os.getcwd(), "zhaoolee_github_garss_subscription_list_v1.opml"), 'w',
              encoding='utf-8') as load_f:
        load_f.write(zhaoolee_github_garss_subscription_list_v1)

    # print(result)


def main():
    create_opml()
    new_read_me = replace_readme()
    cp_readme_md_to_docs()
    cp_media_to_docs()
    email_list = get_email_list()

    mail_re = r'é‚®ä»¶å†…å®¹åŒºå¼€å§‹>([.\S\s]*)<é‚®ä»¶å†…å®¹åŒºç»“æŸ'
    re_result = re.findall(mail_re, new_read_me)

    try:
        send_mail(email_list, f"My-Rss-Readeræ¯æ—¥é€Ÿé€’ï¼ˆ{datetime.today().strftime('%Y-%m-%d')}ï¼‰", re_result)
    except Exception as e:
        print("==é‚®ä»¶è®¾ä¿¡æ¯ç½®é”™è¯¯===ã€‹ã€‹", e)


if __name__ == "__main__":
    main()
